{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective**: Load and adapt the data provided and additional\n",
    "\n",
    "Loaded data in the following order:\n",
    "1. [Provided](#1-Provided-data)\n",
    "    - [Corn.paquet](#1.1-Main-dataset---Corn.parquet)\n",
    "    - [Corn futures](#1.2-Corn-Futures)\n",
    "    - [Chemicals](#1.3-Chemicals)\n",
    "    - [Climate](#1.4-Climate)\n",
    "2. [Additional](#2.-Additional-datasets)\n",
    "    - [Agricultural](#2.1-Agricultural-info-in-US)\n",
    "    - [Cropland in US](#1.2-Cropland-use-for-cops-in-all-US)\n",
    "    - [Cropland by state](#2.3-Cropland-use-for-cops-in-each-state)\n",
    "    - [Ethanol produced in US](#2.4-Ethanol-produced-US)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Git path\n",
    "import os \n",
    "CURRENT_PATH = os.getcwd()\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import csv\n",
    "import xlrd\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "from ydata_profiling import ProfileReport\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('../data/'):\n",
    "    os.makedirs('../data/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Provided data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Main dataset - Corn.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corn_raw = pd.read_parquet('../exdata/provided/CORN.parquet/part-00000-79520c00-c34f-45a5-abf4-58866e63cb2f-c000.snappy.parquet')\n",
    "#corn_raw.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check filters and get the main only with the output feature:\n",
    "\n",
    "1.            FILTER the dataset for STATISTICCAT == Area Planted, Acres Harvested, Yield\n",
    "\n",
    "2.            Filter for AGG_LEVEL_DESC == STATE\n",
    "\n",
    "3.            SHORT_DESC == CORN - ACRES PLANTED\n",
    "\n",
    "4.            REFERENCE_PERIOD_DESC == YEAR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All filters applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply filters\n",
    "filter1 = corn_raw[corn_raw['STATISTICCAT_DESC'].isin(['AREA PLANTED','AREA HARVESTED','YIELD'])]\n",
    "filter2 = filter1[filter1['AGG_LEVEL_DESC'] == 'STATE']\n",
    "filter3 = filter2[filter2['SHORT_DESC'] == 'CORN - ACRES PLANTED']\n",
    "filter4 = filter3[filter3['REFERENCE_PERIOD_DESC'] == 'YEAR']\n",
    "#filter4.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if any of the other columns apart from: **'VALUE'**,**'STATISTICCAT_DESC'**, **'LOCATION_DESC'** and **'YEAR'** are relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_filter4 = ProfileReport(filter4)\n",
    "profile_filter4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get main DF from filters\n",
    "maindf = filter4[['VALUE','STATISTICCAT_DESC', 'LOCATION_DESC', 'YEAR']].copy()\n",
    "\n",
    "profile_maindf = ProfileReport(maindf)\n",
    "profile_maindf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking the profiling, there are needed changes in the **VALUE** and **LOCATION_DESC** columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give correct format to value column\n",
    "maindf['VALUE'] = maindf['VALUE'].str.replace(r',[^,]*$', '', regex=True)\n",
    "maindf['VALUE'] = maindf['VALUE'].str.replace(',', '').astype(float)\n",
    "\n",
    "# Only rows with LOCATION_DESC defined\n",
    "maindf = maindf[maindf['LOCATION_DESC'] != 'OTHER STATES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to use each STATISTICCAT_DESC as feature\n",
    "main_output = maindf.pivot(index=['YEAR','LOCATION_DESC'], columns=['STATISTICCAT_DESC'], values='VALUE')\n",
    "main_output.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main with more features besides filters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applied:\n",
    "- FILTER 2: **AGG_LEVEL_DESC** == *STATE*\n",
    "- FILTER 4: **REFERENCE_PERIOD_DESC** == *YEAR*\n",
    "- And take all combinations of **STATISTICCAT_DESC** and **SHORT_DESC** features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter2 = corn_raw[corn_raw['AGG_LEVEL_DESC'] == 'STATE']\n",
    "filter4 = filter2[filter2['REFERENCE_PERIOD_DESC'] == 'YEAR']\n",
    "main = filter4.copy()\n",
    "\n",
    "# remain with the same subset that main\n",
    "main = main[['VALUE','STATISTICCAT_DESC', 'SHORT_DESC', 'LOCATION_DESC', 'YEAR']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give correct format to value column\n",
    "main['VALUE'] = main['VALUE'].str.replace(r',[^,]*$', '', regex=True)\n",
    "main['VALUE'] = main['VALUE'].str.replace(',', '')\n",
    "main['VALUE'] = pd.to_numeric(main['VALUE'], errors='coerce')\n",
    "\n",
    "# Only rows with LOCATION_DESC defined\n",
    "main = main[main['LOCATION_DESC'] != 'OTHER STATES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to use each SHORT_DESC as feature\n",
    "main_pivot = main.pivot_table(index=['YEAR','LOCATION_DESC'], columns=['SHORT_DESC'], values='VALUE')\n",
    "\n",
    "# Filter by y data -> CORN - ACRES PLANTED\n",
    "main_pivot.dropna(subset=['CORN - ACRES PLANTED'], inplace=True)\n",
    "\n",
    "main_pivot.reset_index(inplace=True)\n",
    "main_pivot = main_pivot.rename_axis(None, axis=1)\n",
    "\n",
    "main_pivot"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save main datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output.to_pickle('../data/main_output.pkl')\n",
    "main_pivot.to_pickle('../data/main.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Corn Futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures_raw = pd.read_csv('../exdata/provided/Corn_Futures.csv')\n",
    "\n",
    "# save only values for mean calculated from HIGH and LOW\n",
    "futures_raw = futures_raw.assign(Futures = (futures_raw['High'] + futures_raw['Low'])/2)\n",
    "\n",
    "# Rename column date\n",
    "futures = futures_raw[['Date', 'Futures']].copy()\n",
    "rename_cols = {'Date': 'DATE'}\n",
    "futures.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# Format date format equally than in main df\n",
    "futures['DATE'] = pd.to_datetime(futures['DATE'], format='%m/%d/%Y')\n",
    "futures['DATE'] = futures['DATE'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Ver correlaci칩n de media/mediana/sd con estado por a침o\n",
    "futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "futures.to_pickle('../data/futures.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Chemicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem = pd.read_excel('../exdata/provided/WPU0652013A.xls', index_col=None, na_values=['NA'], usecols=\"A,B\", skiprows=10)\n",
    "\n",
    "# Rename column date\n",
    "rename_cols = {'observation_date': 'DATE', 'WPU0652013A': 'chem'}\n",
    "chem.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# Ver correlaci칩n de media/mediana/sd con estado por a침o\n",
    "chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chem.to_pickle('../data/chem.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary with all subfolders and pathfiles\n",
    "\n",
    "pathfiles_dict = {}\n",
    "files_dict = {}\n",
    "\n",
    "for folder_path, folders, files in os.walk('../exdata/provided/Climate/'):\n",
    "    # Create a list to store filenames for the current subfolder\n",
    "    subfolder_filenames = []\n",
    "    for file in files:\n",
    "        # Append the filename to the list\n",
    "        subfolder_filenames.append(os.path.join(folder_path, file))\n",
    "    # Store the list of filenames in the dictionary with the subfolder path as the key\n",
    "    pathfiles_dict[folder_path] = subfolder_filenames\n",
    "\n",
    "pathfiles_dict.pop('../exdata/provided/Climate/')\n",
    "\n",
    "prefix_to_remove = '../exdata/provided/Climate/'\n",
    "for key in pathfiles_dict:\n",
    "    updated_key = key.replace(prefix_to_remove, '', 1)\n",
    "    files_dict[updated_key] = pathfiles_dict[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframe of all metrics and pivot it\n",
    "\n",
    "metric = pd.DataFrame()\n",
    "\n",
    "def get_start_row(file):\n",
    "    with open(file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for i, row in enumerate(reader):\n",
    "            # Check if the row matches the condition\n",
    "            if row[0] == 'Date':\n",
    "                start_row = i\n",
    "                break\n",
    "    return start_row\n",
    "\n",
    "for key in files_dict.keys():\n",
    "    for file in files_dict[key]:\n",
    "        if file.endswith('.csv'):  # Check if the file is a CSV file\n",
    "            # Read state and metric info\n",
    "            df = pd.read_csv(file, nrows=1, header=None)\n",
    "            # Find in which row starts the values\n",
    "            start_row = get_start_row(file)\n",
    "            # Append the data to the main dataframe\n",
    "            temp_df = pd.read_csv(file, skiprows = start_row, header=0)\n",
    "            temp_df = temp_df.assign(State = df[0][0], Metric = df[1][0])\n",
    "            metric = metric.append(temp_df, ignore_index=True)\n",
    "\n",
    "\n",
    "# remove anomaly column and rename Date\n",
    "metric = metric.drop('Anomaly', axis=1)\n",
    "rename_cols = {'Date': 'DATE'}\n",
    "metric.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "# pivot to get climate df\n",
    "climate = metric.pivot(index=['DATE','State'], columns='Metric', values='Value')\n",
    "climate.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format date format equally than in main df  - here only year and month\n",
    "climate['DATE'] = pd.to_datetime(climate['DATE'], format='%Y%m')\n",
    "climate['DATE'] = climate['DATE'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Ver correlaci칩n de media/mediana/sd con estado por a침o\n",
    "climate = climate.rename_axis(None, axis=1)\n",
    "climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "climate.to_pickle('../data/climate.pkl')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Additional datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Links with info about this data can be found in:\n",
    "- Agricultural info in US:\n",
    "- Cropland in US and by state:\n",
    "- Ethanol consumed: "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Agricultural info in US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read exdata\n",
    "agriculture = pd.read_excel('../exdata/additional/table01.xlsx', index_col=None, skiprows=2)\n",
    "agriculture = agriculture.iloc[:72]\n",
    "\n",
    "# Adapt colname YEAR\n",
    "rename_cols = {'Year': 'YEAR'}\n",
    "agriculture.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "agriculture.to_pickle('../data/agriculture.pkl')\n",
    "agriculture"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Cropland use for cops in all US "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read exdata\n",
    "cropland_us = pd.read_excel('../exdata/additional/summary_Table_3_cropland_used_for_crops_19102022_update.xlsx', skiprows=1)\n",
    "cropland_us = cropland_us.iloc[:113]\n",
    "\n",
    "# Fill nas\n",
    "cropland_us = cropland_us.fillna(cropland_us.median())\n",
    "\n",
    "# Adapt colname YEAR\n",
    "cropland_us.at[cropland_us.index[-1], 'Year 1/'] = 2022\n",
    "rename_cols = {'Year 1/': 'YEAR'}\n",
    "cropland_us.rename(columns=rename_cols, inplace=True)\n",
    "\n",
    "cropland_us.to_pickle('../data/cropland_us.pkl')\n",
    "cropland_us"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Cropland use for cops in each state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read exdata\n",
    "cropland_state = pd.read_excel('../exdata/additional/Cropland_used_for_crops_19452012_by_state.xls', index_col=None, skiprows=2)\n",
    "cropland_state = cropland_state.iloc[4:72]\n",
    "\n",
    "# Filter empty rows\n",
    "cropland_state = cropland_state.dropna()\n",
    "\n",
    "# Fill years\n",
    "cropland_state.set_index('Regions and States', inplace=True)\n",
    "\n",
    "# Create columns for all intermediate years\n",
    "cropland_state.columns = cropland_state.columns.astype(str)\n",
    "years = [int(col) for col in cropland_state.columns]\n",
    "for idx, year in enumerate(range(min(years), max(years)+4)):\n",
    "    if str(year) in cropland_state.columns:\n",
    "        last = cropland_state.iloc[:, idx]\n",
    "    if str(year) not in cropland_state.columns:\n",
    "        cropland_state.insert(idx, year, last)\n",
    "\n",
    "cropland_state = cropland_state.reset_index()\n",
    "\n",
    "# Melt df\n",
    "df_dropped = cropland_state.drop('Regions and States', axis=1)\n",
    "cropland_state_melted = pd.melt(cropland_state, id_vars='Regions and States', value_vars=df_dropped,\n",
    "                                                var_name='YEAR', value_name='VALUE')\n",
    "\n",
    "cropland_state = cropland_state_melted.copy()\n",
    "cropland_state.to_pickle('../data/cropland_state.pkl')\n",
    "cropland_state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Ethanol produced US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read exdata\n",
    "ethanol = pd.read_excel('../exdata/additional/PET_PNP_OXY_A_EPOOXE_YOP_MBBLPD_A.xls', sheet_name = 'Data 1', index_col=None, skiprows=2)\n",
    "\n",
    "# Adapt colname YEAR\n",
    "rename_cols = {'Date': 'YEAR'}\n",
    "ethanol.rename(columns=rename_cols, inplace=True)\n",
    "ethanol['YEAR'] = pd.to_datetime(ethanol['YEAR'], format='%Y%m%d')\n",
    "ethanol['YEAR'] = ethanol['YEAR'].dt.strftime('%Y')\n",
    "\n",
    "# Fill nas\n",
    "ethanol = ethanol.fillna(ethanol.median())\n",
    "#ethanol.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map per region\n",
    "df = ethanol.drop('U.S. Oxygenate Plant Production of Fuel Ethanol (Thousand Barrels per Day)', axis=1)\n",
    "df.columns = df.columns.str.replace(r' \\(.+$', '', regex=True)\n",
    "\n",
    "df = pd.melt(df, id_vars='YEAR', value_vars=df,\n",
    "                var_name='region', value_name='value')\n",
    "                                                \n",
    "\n",
    "region_to_state_map = {'East Coast': ['Connecticut', 'Delaware', 'Florida', 'Georgia', 'Maine', 'Maryland',\n",
    "                                     'Massachusetts', 'New Hampshire', 'New Jersey', 'New York', 'North Carolina',\n",
    "                                     'Pennsylvania', 'Rhode Island', 'South Carolina', 'Virginia'],\n",
    "                      'Midwest': ['Illinois', 'Indiana', 'Iowa', 'Kansas', 'Michigan', 'Minnesota', 'Missouri',\n",
    "                                  'Nebraska', 'North Dakota', 'Ohio', 'South Dakota', 'Wisconsin'],\n",
    "                      'Gulf Coast': ['Alabama', 'Louisiana', 'Mississippi', 'Texas'],\n",
    "                      'Rocky Mountain': ['Arizona', 'Colorado', 'Idaho', 'Montana', 'Nevada', 'New Mexico',\n",
    "                                         'Utah', 'Wyoming'],\n",
    "                      'West Coast': ['Alaska', 'California', 'Oregon', 'Washington']}\n",
    "\n",
    "\n",
    "# Create a new DataFrame to store the results\n",
    "per_region_df = pd.DataFrame(columns=['state', 'region', 'ethanol', 'YEAR'])\n",
    "\n",
    "# Iterate through each row in the original DataFrame\n",
    "for _, row in df.iterrows():\n",
    "    # Get the region, value, and year values for the current row\n",
    "    region = row['region']\n",
    "    value = row['value']\n",
    "    year = row['YEAR']\n",
    "    # Get the corresponding states for the region from the reverse mapping\n",
    "    states_for_region = region_to_state_map.get(region, [])\n",
    "    # Iterate through the states and create a new row for each state\n",
    "    for state in states_for_region:\n",
    "        # Create a new row with the state, region, value, and year values\n",
    "        new_row = pd.Series({'state': state, 'region': region, 'ethanol': value, 'YEAR': year})\n",
    "        # Append the new row to the result DataFrame\n",
    "        per_region_df = per_region_df.append(new_row, ignore_index=True)\n",
    "\n",
    "#per_region_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add again value in all us\n",
    "df_ethanol = ethanol[['YEAR','U.S. Oxygenate Plant Production of Fuel Ethanol (Thousand Barrels per Day)']]\n",
    "\n",
    "df_ethanol = pd.melt(df_ethanol, id_vars='YEAR',\n",
    "                                 value_vars='U.S. Oxygenate Plant Production of Fuel Ethanol (Thousand Barrels per Day)',\n",
    "                                 var_name='all_regions', value_name='U.S. ethanol')\n",
    "\n",
    "df_ethanol = df_ethanol.drop(['all_regions'], axis=1)\n",
    "\n",
    "ethanol_merged = pd.merge(per_region_df, df_ethanol, on='YEAR', how='inner')\n",
    "ethanol = ethanol_merged.copy()\n",
    "\n",
    "ethanol.to_pickle('../data/ethanol.pkl')\n",
    "ethanol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
